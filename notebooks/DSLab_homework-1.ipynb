{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Data Wrangling with Hadoop\n",
    "\n",
    "The goal of this assignment is to put into action the data wrangling techniques from the exercises of week-3 and week-4. We highly suggest you to finish these two exercises first and then start the homework. In this homework, we are going to reuse the same __sbb__ dataset as we see in two exercises. \n",
    "\n",
    "Try to use as much as HiveQL as possible and use pandas operations only when it's necessary.\n",
    "\n",
    "__Hand-in:__\n",
    "- __Due: 24.03.2020 23:59 CET__\n",
    "- `git push` your final verion to your group's Renku repository before the due\n",
    "- check if `Dockerfile`, `environment.yml` and `requirements.txt` are properly written\n",
    "- add necessary comments and discussion to make your queries readable\n",
    "\n",
    "\n",
    "__Cluster Usage__\n",
    "\n",
    "As there are many of you working with the cluster, we encourage you to prototype your queries on small data samples before running them on whole datasets.\n",
    "\n",
    "__Documentation__\n",
    "\n",
    "Hive queries: <https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select>\n",
    "\n",
    "Hive functions: <https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyhive import hive\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "# create connection\n",
    "conn = hive.connect(host='iccluster059.iccluster.epfl.ch', port=10000, username=username) \n",
    "# create cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from SBB/CFF/FFS\n",
    "\n",
    "Data source: <https://opentransportdata.swiss/en/dataset/istdaten>\n",
    "\n",
    "In this part, you will leverage Hive to perform exploratory analysis of data published by the [Open Data Platform Swiss Public Transport](https://opentransportdata.swiss).\n",
    "\n",
    "Format: the dataset is originally presented as a collection of textfiles with fields separated by ';' (semi-colon). For efficiency, the textfiles have been compressed into Optimized Row Columnar ([ORC](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)) file format. \n",
    "\n",
    "Location: you can find the data in ORC format on HDFS at the path `/data/sbb/orc/istdaten`.\n",
    "\n",
    "The full description from opentransportdata.swiss can be found in <https://opentransportdata.swiss/de/cookbook/ist-daten/> in four languages. Because of the translation typos there may be some misunderstandings. We suggest you rely on the German version and use an automated translator when necessary. We will clarify if there is still anything unclear in class and Slack. Here are the relevant column descriptions:\n",
    "\n",
    "- `BETRIEBSTAG`: date of the trip\n",
    "- `FAHRT_BEZEICHNER`: identifies the trip\n",
    "- `BETREIBER_ABK`, `BETREIBER_NAME`: operator (name will contain the full name, e.g. Schweizerische Bundesbahnen for SBB)\n",
    "- `PRODUKT_ID`: type of transport, e.g. train, bus\n",
    "- `LINIEN_ID`: for trains, this is the train number\n",
    "- `LINIEN_TEXT`,`VERKEHRSMITTEL_TEXT`: for trains, the service type (IC, IR, RE, etc.)\n",
    "- `ZUSATZFAHRT_TF`: boolean, true if this is an additional trip (not part of the regular schedule)\n",
    "- `FAELLT_AUS_TF`: boolean, true if this trip failed (cancelled or not completed)\n",
    "- `HALTESTELLEN_NAME`: name of the stop\n",
    "- `ANKUNFTSZEIT`: arrival time at the stop according to schedule\n",
    "- `AN_PROGNOSE`: actual arrival time\n",
    "- `AN_PROGNOSE_STATUS`: show how the actual arrival time is calcluated\n",
    "- `ABFAHRTSZEIT`: departure time at the stop according to schedule\n",
    "- `AB_PROGNOSE`: actual departure time\n",
    "- `AB_PROGNOSE_STATUS`: show how the actual departure time is calcluated\n",
    "- `DURCHFAHRT_TF`: boolean, true if the transport does not stop there\n",
    "\n",
    "Each line of the file represents a stop and contains arrival and departure times. When the stop is the start or end of a journey, the corresponding columns will be empty (`ANKUNFTSZEIT`/`ABFAHRTSZEIT`).\n",
    "\n",
    "In some cases, the actual times were not measured so the `AN_PROGNOSE_STATUS`/`AB_PROGNOSE_STATUS` will be empty or set to `PROGNOSE` and `AN_PROGNOSE`/`AB_PROGNOSE` will be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get yourself ready\n",
    "\n",
    "If you have gone through the exercises by yourself, you are free to go for the questions. If you haven't gone through the exercises, you can follow the next two cells to get all your databases and tables ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In Shell__:\n",
    "\n",
    "```bash\n",
    "hdfs dfs -mkdir   -p                              /user/${JUPYTERHUB_USER}/hive\n",
    "\n",
    "hdfs dfs -setfacl -m    user:hive:r-x             /user/${JUPYTERHUB_USER}\n",
    "\n",
    "hdfs dfs -setfacl -R -m group::r-x                /user/${JUPYTERHUB_USER}\n",
    "\n",
    "hdfs dfs -setfacl -R -m other::---                /user/${JUPYTERHUB_USER}\n",
    "\n",
    "hdfs dfs -setfacl -R -m default:group::r-x        /user/${JUPYTERHUB_USER}\n",
    "\n",
    "hdfs dfs -setfacl -R -m default:other::---        /user/${JUPYTERHUB_USER}\n",
    "\n",
    "hdfs dfs -setfacl -m    user:hive:rwx             /user/${JUPYTERHUB_USER}/hive\n",
    "\n",
    "hdfs dfs -setfacl -m    default:user:hive:rwx     /user/${JUPYTERHUB_USER}/hive\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In Python__:\n",
    "```python\n",
    "# Drop your database\n",
    "query = \"\"\"\n",
    "    drop database if exists {0} cascade\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Create your database\n",
    "query = \"\"\"\n",
    "    create database {0} location \"/user/{0}/hive\"\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Drop the sbb table\n",
    "query = \"\"\"\n",
    "    drop table if exists {0}.sbb_orc\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Create the sbb table\n",
    "query = \"\"\"\n",
    "    create external table {0}.sbb_orc(\n",
    "        BETRIEBSTAG string,\n",
    "        FAHRT_BEZEICHNER string,\n",
    "        BETREIBER_ID string,\n",
    "        BETREIBER_ABK string,\n",
    "        BETREIBER_NAME string,\n",
    "        PRODUKT_ID string,\n",
    "        LINIEN_ID string,\n",
    "        LINIEN_TEXT string,\n",
    "        UMLAUF_ID string,\n",
    "        VERKEHRSMITTEL_TEXT string,\n",
    "        ZUSATZFAHRT_TF string,\n",
    "        FAELLT_AUS_TF string,\n",
    "        BPUIC string,\n",
    "        HALTESTELLEN_NAME string,\n",
    "        ANKUNFTSZEIT string,\n",
    "        AN_PROGNOSE string,\n",
    "        AN_PROGNOSE_STATUS string,\n",
    "        ABFAHRTSZEIT string,\n",
    "        AB_PROGNOSE string,\n",
    "        AB_PROGNOSE_STATUS string,\n",
    "        DURCHFAHRT_TF string\n",
    "    )\n",
    "    row format delimited fields terminated by ';'\n",
    "    stored as ORC\n",
    "    location '/data/sbb/orc/istdaten'\n",
    "    tblproperties (\"skip.header.line.count\"=\"1\")\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Drop the table of one day\n",
    "query = \"\"\"\n",
    "    drop table if exists {0}.sbb_05_11_2018\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Create the table of one day\n",
    "query = \"\"\"\n",
    "    create table {0}.sbb_05_11_2018\n",
    "    stored as orc\n",
    "    as \n",
    "        select *\n",
    "        from {0}.sbb_orc\n",
    "        where BETRIEBSTAG like '05_11_2018'\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop your database\n",
    "query = \"\"\"\n",
    "    drop database if exists {0} cascade\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Create your database\n",
    "query = \"\"\"\n",
    "    create database {0} location \"/user/{0}/hive\"\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Drop the sbb table\n",
    "query = \"\"\"\n",
    "    drop table if exists {0}.sbb_orc\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Create the sbb table\n",
    "query = \"\"\"\n",
    "    create external table {0}.sbb_orc(\n",
    "        BETRIEBSTAG string,\n",
    "        FAHRT_BEZEICHNER string,\n",
    "        BETREIBER_ID string,\n",
    "        BETREIBER_ABK string,\n",
    "        BETREIBER_NAME string,\n",
    "        PRODUKT_ID string,\n",
    "        LINIEN_ID string,\n",
    "        LINIEN_TEXT string,\n",
    "        UMLAUF_ID string,\n",
    "        VERKEHRSMITTEL_TEXT string,\n",
    "        ZUSATZFAHRT_TF string,\n",
    "        FAELLT_AUS_TF string,\n",
    "        BPUIC string,\n",
    "        HALTESTELLEN_NAME string,\n",
    "        ANKUNFTSZEIT string,\n",
    "        AN_PROGNOSE string,\n",
    "        AN_PROGNOSE_STATUS string,\n",
    "        ABFAHRTSZEIT string,\n",
    "        AB_PROGNOSE string,\n",
    "        AB_PROGNOSE_STATUS string,\n",
    "        DURCHFAHRT_TF string\n",
    "    )\n",
    "    row format delimited fields terminated by ';'\n",
    "    stored as ORC\n",
    "    location '/data/sbb/orc/istdaten'\n",
    "    tblproperties (\"skip.header.line.count\"=\"1\")\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Drop the table of one day\n",
    "query = \"\"\"\n",
    "    drop table if exists {0}.sbb_05_11_2018\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "# Create the table of one day\n",
    "query = \"\"\"\n",
    "    create table {0}.sbb_05_11_2018\n",
    "    stored as orc\n",
    "    as \n",
    "        select *\n",
    "        from {0}.sbb_orc\n",
    "        where BETRIEBSTAG like '05_11_2018'\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question I.a - 5 Points\n",
    "\n",
    "In the exercise, you were asked to find how many stops of each type of transportation for the date 05.11.2018. Now, let's do the same for the whole dataset. \n",
    "\n",
    "Show the results with a stacked bar chart (you can use `pandas` to create a pivot table if necessary). Document any patterns you can see.\n",
    "\n",
    "__Hint__: \n",
    "- To properly order by date, you may have to parse them using the `unix_timestamp` function.\n",
    "- When using `pd.read_sql(query, conn, ...)` to retrieve the query results, there is one `parse_dates` argument for date parsing.\n",
    "- If you think it is not nice to display all the data in one plot, you can select a small period of data, i.e. 3 months, for visualization to detect the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question I.b - 10 Points\n",
    "\n",
    "Get the set of IC (`VERKEHRSMITTEL_TEXT`) trains you can take to go (without connections) from Genève to Lausanne on a typical week day (not Saturday, not Sunday, not a bank holiday). Display the train number (`LINIEN_ID`) as well as the schedule of the trains.\n",
    "\n",
    "__Note:__ do not hesitate to create intermediary tables. You can use the advanced search of SBB's website to check your answer, the schedule of IC from Genève to Lausanne has not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question I.c - 10 Points\n",
    "\n",
    "In the exercise, we discussed a little bit about two interesting status, `AN_PROGNOSE_STATUS` and `AB_PROGNOSE_STATUS`. We will continue here to see how things evolved in the past two years.\n",
    "\n",
    "i) Please show us how the monthly distribution of `AN_PROGNOSE_STATUS` (arrival forcast status) for __IC 733__ train at the Lausanne station changes over time, i.e., how many of them are REAL, GESCHAETZT, etc. in every month. Use `pandas` to create a pivot table if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Show how the monthly distribution of `AN_PROGNOSE_STATUS` for all the trains that arrived at Lausanne station. Document any anything you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question I.d - 20 Points\n",
    "\n",
    "In this question, use __REAL__ for `AN_PROGNOSE_STATUS` and `AB_PROGNOSE_STATUS`.\n",
    "\n",
    "i) Display the distribution of delays for the __IC 733__ train at the Lausanne train station. Select the information from the database as a \"histogram\" with bin size of one minute and plot it in a proper way.\n",
    "\n",
    "__Note:__ when the train is ahead of schedule, count this as a delay of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Compute the 50th and 75th percentiles of delays for IC 702, 704, ..., 728, 730 (15 trains total) at Genève main station. Which trains are the most disrupted? Can you find the tendency and interpret?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Compute 25th, 50th and 75th percentiles of delays for all trains departing Lausanne gare within each hour and visualize your results. Can you find the tendency and interpret?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv) Did you notice something \"strange\"? Can you try to find the reasons behind that? Feel free to check it out from different perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question I.f - 15 Points\n",
    "\n",
    "If the departure time of one train is delayed, can it catch up with the schedule at a later station? Select __at least 2 trains from Genève (main station) to Lausanne gare__ as examples. Think about what kind of trains you want to select, direct or indirect (having stops in between), at rush hour or in midnight? Use HiveQL to select relevant data and show the results with a proper plot of arrival delay at Lausanne versus departure delay at Genève. Document and discuss your findings.\n",
    "\n",
    "__Note__: you can write some helper functions to generate the query for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM {0}.sbb_orc\n",
    "    LIMIT 500\n",
    "\"\"\".format(username)\n",
    "pd.read_sql(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
